{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install opencv-python matplotlib tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:44:16.754539: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-09 14:44:16.772568: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-09 14:44:16.778076: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-09-09 14:44:16.792044: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-09 14:44:17.678030: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer, Input, Conv2D, MaxPooling2D, Input, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set GPU Growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:44:18.320664: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_UNKNOWN: unknown error\n",
      "2024-09-09 14:44:18.320694: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:135] retrieving CUDA diagnostic information for host: nitro\n",
      "2024-09-09 14:44:18.320701: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:142] hostname: nitro\n",
      "2024-09-09 14:44:18.320809: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:166] libcuda reported version is: 535.183.1\n",
      "2024-09-09 14:44:18.320830: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:170] kernel reported version is: 535.183.1\n",
      "2024-09-09 14:44:18.320836: I external/local_xla/xla/stream_executor/cuda/cuda_diagnostics.cc:249] kernel version seems to match DSO: 535.183.1\n"
     ]
    }
   ],
   "source": [
    "#avoid out of memory erros by setting GPU memory growth\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folder structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_PATH = os.path.join(\"data\", \"positive\")\n",
    "NEG_PATH = os.path.join(\"data\", \"negative\")\n",
    "ANC_PATH = os.path.join(\"data\", \"anchor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(POS_PATH, exist_ok=True)\n",
    "os.makedirs(NEG_PATH, exist_ok=True)\n",
    "os.makedirs(ANC_PATH, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tfds.core.DatasetInfo(\n",
      "    name='lfw',\n",
      "    full_name='lfw/0.1.0',\n",
      "    description=\"\"\"\n",
      "    Labeled Faces in the Wild: A Database for Studying Face Recognition in\n",
      "    Unconstrained Environments\n",
      "    \"\"\",\n",
      "    homepage='http://vis-www.cs.umass.edu/lfw',\n",
      "    data_dir='/home/andersonc/tensorflow_datasets/lfw/0.1.0',\n",
      "    file_format=tfrecord,\n",
      "    download_size=172.20 MiB,\n",
      "    dataset_size=180.28 MiB,\n",
      "    features=FeaturesDict({\n",
      "        'image': Image(shape=(250, 250, 3), dtype=uint8),\n",
      "        'label': Text(shape=(), dtype=string),\n",
      "    }),\n",
      "    supervised_keys=('label', 'image'),\n",
      "    disable_shuffling=False,\n",
      "    splits={\n",
      "        'train': <SplitInfo num_examples=13233, num_shards=2>,\n",
      "    },\n",
      "    citation=\"\"\"@TechReport{LFWTech,\n",
      "        author = {Gary B. Huang and Manu Ramesh and Tamara Berg and Erik Learned-Miller},\n",
      "        title = {Labeled Faces in the Wild: A Database for Studying Face Recognition in Unconstrained Environments},\n",
      "        institution = {University of Massachusetts, Amherst},\n",
      "        year = 2007,\n",
      "        number = {07-49},\n",
      "        month = {October}\n",
      "    }\"\"\",\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "lfw_dataset, info = tfds.load('lfw', split='train', with_info=True, as_supervised=True)\n",
    "\n",
    "# Display dataset information\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All images have been moved to the data/negative directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:44:33.144158: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# Function to save images to a directory\n",
    "def save_image(image, index, directory):\n",
    "    # Convert the image tensor to a NumPy array and then to uint8\n",
    "    image_np = tf.image.convert_image_dtype(image, dtype=tf.uint8).numpy()\n",
    "\n",
    "    # Encode image in JPEG format\n",
    "    image_encoded = tf.image.encode_jpeg(image_np)\n",
    "    \n",
    "    # Define the path to save the image\n",
    "    image_path = os.path.join(directory, f'image_{index}.jpg')\n",
    "    \n",
    "    # Write the image to the file\n",
    "    tf.io.write_file(image_path, image_encoded)\n",
    "\n",
    "# Move all images to the negative directory\n",
    "for index, (label, image) in enumerate(lfw_dataset):\n",
    "    save_image(image, index, NEG_PATH)\n",
    "\n",
    "print(f\"All images have been moved to the {NEG_PATH} directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colect Positive and Anchor Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cap = cv2.VideoCapture(0)\n",
    "# while cap.isOpened():\n",
    "#     ret, frame = cap.read()\n",
    "#     if not ret:\n",
    "#         print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "#         break\n",
    "\n",
    "#     cv2.imshow('frame', frame)\n",
    "#     if cv2.waitKey(1) & 0XFF == ord('q'):\n",
    "#         break\n",
    "\n",
    "#     if cv2.waitKey(1) & 0XFF == ord('p'):\n",
    "#         cv2.imwrite(os.path.join(POS_PATH, f\"image_{random.randint(0, 1000)}.jpg\"), frame)  \n",
    "    \n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved frame to data/anchor/30230f92-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/30a0edf4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/30bb131e-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/30d3157c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/30ee6138-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3120004e-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/313a2bc2-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/315755bc-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/316ff95a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/318a1f74-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/31c9ec08-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/31e721ba-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/32015cce-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/323e67ae-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/32763bc0-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/32ae920e-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/32c97e16-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/32e5193c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/32fc8f9a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/331a10b0-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/33332d2a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/334d32c4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/anchor/335271da-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/336b4930-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/33855744-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/33bde2d0-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/anchor/33c8eaa4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/33dc466c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/33fa9fc2-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/34141a1a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/344c2bbc-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/346bce04-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3606beb8-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/361e6ffe-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/363dc2dc-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3659ca7c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3676332e-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/369361ce-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/36d0f7dc-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/36ea3d46-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3708b938-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/anchor/37122e00-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3723ed7a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/375c012e-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/37761424-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/37926a66-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/37ad4b1a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/37c6e2b4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/380356ae-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/38223df8-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/383c3276-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3879bb96-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3897db30-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/38b6b00a-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3987a3cc-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/39a6b208-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/39c5c04e-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/39decec2-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/39fbf86c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3a1beb54-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3a354d74-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3a544e22-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3a733364-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3a921aae-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3aaff18c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3acb9f72-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3b038888-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3b3f997c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3b5e31b6-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3b7cec96-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3b9b51cc-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3bf25166-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3c10c538-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3c4b606c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3c68756c-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3c829d52-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3ca20430-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3ce0be96-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3cfac368-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3d1758d4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3d2f88d2-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3d4ec4f4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3d6ef616-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3d8af6f4-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3da9ff40-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3de876da-6ed3-11ef-98bd-dc215cb50b44.jpg\n",
      "Saved frame to data/positive/3e066cda-6ed3-11ef-98bd-dc215cb50b44.jpg\n"
     ]
    }
   ],
   "source": [
    "#Haar cascade for face detection\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        (x, y, w, h) = faces[0] \n",
    "        center_x, center_y = x + w // 2, y + h // 2\n",
    "        \n",
    "        # Define the dimensions for the centered crop\n",
    "        half_width = 125  # Half of the target width 250\n",
    "        half_height = 125  # Half of the target height 250\n",
    "\n",
    "        \n",
    "        start_x = max(center_x - half_width, 0)\n",
    "        start_y = max(center_y - half_height, 0)\n",
    "        end_x = min(center_x + half_width, frame.shape[1])\n",
    "        end_y = min(center_y + half_height, frame.shape[0])\n",
    "        \n",
    "        \n",
    "        cropped_frame = frame[start_y:end_y, start_x:end_x]\n",
    "        \n",
    "        \n",
    "        resized_frame = cv2.resize(cropped_frame, (250, 250))\n",
    "    else:\n",
    "        \n",
    "        resized_frame = cv2.resize(frame, (250, 250))\n",
    "    \n",
    "    \n",
    "    cv2.imshow('frame', resized_frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('p'):\n",
    "        image_path = os.path.join(POS_PATH, f\"{uuid.uuid1()}.jpg\")\n",
    "        cv2.imwrite(image_path, resized_frame)\n",
    "        print(f\"Saved frame to {image_path}\")\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('a'):\n",
    "        image_path = os.path.join(ANC_PATH, f\"{uuid.uuid1()}.jpg\")\n",
    "        cv2.imwrite(image_path, resized_frame)\n",
    "        print(f\"Saved frame to {image_path}\")\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and process images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor = tf.data.Dataset.list_files(ANC_PATH + \"/*.jpg\").take(30)\n",
    "positive = tf.data.Dataset.list_files(POS_PATH + \"/*.jpg\").take(30)\n",
    "negative = tf.data.Dataset.list_files(NEG_PATH + \"/*.jpg\").take(30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/anchor/bef14674-67be-11ef-8b57-dc215cb50b44.jpg\n"
     ]
    }
   ],
   "source": [
    "dir_test = anchor.as_numpy_iterator().next().decode(\"utf-8\")\n",
    "print(dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(file_path):\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, [100, 100])\n",
    "    img = img / 255.0\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = preprocess_image(dir_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create labelled dataset\n",
    "\n",
    "class_labels = tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))\n",
    "iterator_labs = class_labels.as_numpy_iterator()\n",
    "iterator_labs.next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = tf.data.Dataset.zip((anchor, positive, tf.data.Dataset.from_tensor_slices(tf.ones(len(anchor)))))\n",
    "negatives = tf.data.Dataset.zip((anchor, negative, tf.data.Dataset.from_tensor_slices(tf.zeros(len(anchor)))))\n",
    "dataset = tf.data.Dataset.concatenate(positives, negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = dataset.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(b'data/anchor/c3ca9682-67be-11ef-8b57-dc215cb50b44.jpg',\n",
       " b'data/positive/3d15c09e-67c3-11ef-80ac-dc215cb50b44.jpg',\n",
       " 1.0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_twin(input_img, validatioin_img, label):\n",
    "    return preprocess_image(input_img), preprocess_image(validatioin_img), label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = process_twin(*samples.next())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build dataloader pipeline\n",
    "\n",
    "dataset = dataset.map(process_twin)\n",
    "dataset = dataset.cache()\n",
    "dataset = dataset.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training  partitions\n",
    "train_data = dataset.take(round(len(dataset)*0.8))\n",
    "train_data = train_data.batch(16)\n",
    "train_data = train_data.prefetch(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing partitions\n",
    "test_data = dataset.skip(round(len(dataset)*0.8))\n",
    "test_data = test_data.take(round(len(dataset)*0.2))\n",
    "test_data = test_data.batch(16)\n",
    "test_data = test_data.prefetch(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_embedding():\n",
    "    input = Input(shape=(100, 100, 3), name=\"input_image\")\n",
    "    c1 = Conv2D(64, (10, 10), activation='relu')(input)\n",
    "    m1 = MaxPooling2D(64, (2, 2), padding='same')(c1)\n",
    "\n",
    "    c2 = Conv2D(128, (7, 7), activation='relu')(m1)\n",
    "    m2 = MaxPooling2D(64, (2, 2), padding='same')(c2)\n",
    "\n",
    "    c3 = Conv2D(128, (4, 4), activation='relu')(m2)\n",
    "    m3 = MaxPooling2D(64, (2, 2), padding='same')(c3)\n",
    "\n",
    "    c4 = Conv2D(256, (4, 4), activation='relu')(m3)\n",
    "    f = Flatten()(c4)\n",
    "    d1 = Dense(4096, activation='sigmoid')(f)\n",
    "    return Model(inputs=[input], outputs=[d1], name=\"embedding\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_embedding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"embedding\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"embedding\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">91</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">19,264</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">46</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">401,536</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">37,752,832</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_image (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m91\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m19,264\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m46\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m401,536\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │       \u001b[38;5;34m262,272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m9\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)      │       \u001b[38;5;34m524,544\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)           │    \u001b[38;5;34m37,752,832\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> (148.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,960,448\u001b[0m (148.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> (148.62 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,960,448\u001b[0m (148.62 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Siamese L1 Distance Class\n",
    "class L1Dist(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "    def call(self, input_embedding, validation_embedding):\n",
    "        input_embedding = tf.convert_to_tensor(input_embedding)\n",
    "        validation_embedding = tf.convert_to_tensor(validation_embedding)\n",
    "        return tf.math.abs(input_embedding - validation_embedding)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Siamese Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_image = Input(name='input_img', shape=(100,100,3))\n",
    "validation_image = Input(name='validation_img', shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_embedding = model(input_image)\n",
    "val_embedding = model(validation_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<KerasTensor shape=(None, 4096), dtype=float32, sparse=False, name=keras_tensor_9>]\n"
     ]
    }
   ],
   "source": [
    "print(inp_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_layer = L1Dist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances = siamese_layer(inp_embedding, val_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model():\n",
    "    input = Input(shape=(100, 100, 3), name=\"input_image\")\n",
    "    validation = Input(shape=(100, 100, 3), name=\"validation_image\")\n",
    "\n",
    "    siamese_layer = L1Dist()\n",
    "    siamese_layer._name = 'distance'\n",
    "    distances = siamese_layer(model(input), model(validation))\n",
    "\n",
    "    classifier = Dense(1, activation='sigmoid')(distances)\n",
    "\n",
    "    return Model(inputs=[input, validation], outputs=[classifier], name=\"siamese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model = siamese_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"siamese\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"siamese\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_image    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">38,960,448</span> │ input_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │                   │            │ validation_image… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">L1Dist</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
       "│                     │                   │            │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,097</span> │ l1_dist_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_image         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ validation_image    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m3\u001b[0m)                │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      │ \u001b[38;5;34m38,960,448\u001b[0m │ input_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mFunctional\u001b[0m)        │                   │            │ validation_image… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ l1_dist_1 (\u001b[38;5;33mL1Dist\u001b[0m)  │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m2\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
       "│                     │                   │            │ embedding[\u001b[38;5;34m3\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;34m1\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │      \u001b[38;5;34m4,097\u001b[0m │ l1_dist_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,964,545</span> (148.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,964,545\u001b[0m (148.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "binary_cross_loss = tf.losses.BinaryCrossentropy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#checkpoints\n",
    "\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(optimizer=opt, model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = train_data.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = test_batch.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(batch_1[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = batch_1[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 100, 100, 3)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = batch_1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = siamese_model(X, training=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 16, 1), dtype=float32, numpy=\n",
       "array([[[0.50637233],\n",
       "        [0.5008936 ],\n",
       "        [0.5020103 ],\n",
       "        [0.50200874],\n",
       "        [0.5017967 ],\n",
       "        [0.5000565 ],\n",
       "        [0.5014882 ],\n",
       "        [0.5017015 ],\n",
       "        [0.5014063 ],\n",
       "        [0.5021161 ],\n",
       "        [0.5025069 ],\n",
       "        [0.50204635],\n",
       "        [0.5022658 ],\n",
       "        [0.50151914],\n",
       "        [0.5039177 ],\n",
       "        [0.5012044 ]]], dtype=float32)>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.function\n",
    "def train_step(batch):\n",
    "    with tf.GradientTape() as tape:\n",
    "        X = batch[:2]\n",
    "        y = batch[2]\n",
    "\n",
    "        #forward pass\n",
    "        y_pred = siamese_model(X, training=True)\n",
    "        y_pred = tf.squeeze(y_pred, axis=[0, 2])\n",
    "        loss = binary_cross_loss(y, y_pred)\n",
    "    print(f\"Loss: {loss}\")\n",
    "\n",
    "    grad = tape.gradient(loss, siamese_model.trainable_variables)\n",
    "    opt.apply_gradients(zip(grad, siamese_model.trainable_variables))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, EPOCHS):\n",
    "    for epoch in range(1, EPOCHS+1):\n",
    "        print('\\n Epoch {}/{}'.format(epoch, EPOCHS))\n",
    "        progbar = tf.keras.utils.Progbar(len(data))\n",
    "        \n",
    "        for idx, batch in enumerate(data):\n",
    "            train_step(batch)\n",
    "            progbar.update(idx+1)\n",
    "        \n",
    "        if epoch % 10 == 0: \n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1/50\n",
      "Loss: 0.6940973997116089\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.6674364805221558\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.732749342918396\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:45:20.364614: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7333803772926331\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.6774736046791077\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.6211386322975159\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 3/50\n",
      "Loss: 0.5929840803146362\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.6237573623657227\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.567034125328064\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:45:48.719184: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5013681650161743\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.7287524938583374\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.48856231570243835\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 5/50\n",
      "Loss: 0.5199129581451416\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.4955675005912781\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.4547836184501648\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 6/50\n",
      "Loss: 0.45399072766304016\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.35049742460250854\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.36602461338043213\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 7/50\n",
      "Loss: 0.34817177057266235\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.2986963093280792\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.38152793049812317\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:46:43.596691: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.1783258616924286\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.3181908130645752\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.15637484192848206\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 9/50\n",
      "Loss: 0.19016101956367493\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.1354123204946518\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.08228069543838501\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 10/50\n",
      "Loss: 0.08792419731616974\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.08894182741641998\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.14480000734329224\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 11/50\n",
      "Loss: 0.05012156069278717\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.1681365817785263\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.12133382260799408\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 12/50\n",
      "Loss: 0.11855576187372208\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.12374909222126007\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.036481793969869614\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 13/50\n",
      "Loss: 0.04530848562717438\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.08345530182123184\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.029560789465904236\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 14/50\n",
      "Loss: 0.07120835781097412\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.05597470700740814\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.024850990623235703\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 15/50\n",
      "Loss: 0.023021653294563293\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.04241468757390976\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.03427749127149582\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:48:32.365146: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.024458950385451317\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.03476733714342117\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.016237769275903702\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 17/50\n",
      "Loss: 0.0061633652076125145\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.003832070389762521\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.006648017093539238\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 18/50\n",
      "Loss: 0.0028661072719842196\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.0008253723499365151\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.013624824583530426\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 19/50\n",
      "Loss: 0.001538627315312624\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.00442373426631093\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.0017847028793767095\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 20/50\n",
      "Loss: 0.008391511626541615\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.017552653327584267\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.0017918975790962577\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 21/50\n",
      "Loss: 0.002863029483705759\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.0013902026694267988\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.0023309853859245777\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 22/50\n",
      "Loss: 0.004240619018673897\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.0009253502357751131\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.00025596722844056785\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 23/50\n",
      "Loss: 0.0007724026800133288\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.001665847492404282\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 0.0021863360889256\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 24/50\n",
      "Loss: 0.0009876519907265902\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.0025399611331522465\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.0001054925232892856\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 25/50\n",
      "Loss: 0.00029854362946935\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.00042060238774865866\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.0003939331218134612\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 26/50\n",
      "Loss: 9.805543231777847e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.00044909678399562836\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 2.9536124202422798e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 27/50\n",
      "Loss: 0.00014317338354885578\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 4.667422763304785e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.00011372824519639835\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 28/50\n",
      "Loss: 2.812017555697821e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 0.00013803032925352454\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 0.0002282620407640934\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 29/50\n",
      "Loss: 0.0001098483771784231\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 7.13623157935217e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 8.013832848519087e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 30/50\n",
      "Loss: 0.0001609665632713586\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 3.5530996683519334e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 4.483660450205207e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 31/50\n",
      "Loss: 5.491752745001577e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 0.00013145373668521643\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 1.2208020052639768e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:52:10.375982: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 3.382433351362124e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 1.6428877643193118e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 6.37368721072562e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 33/50\n",
      "Loss: 5.9162739489693195e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 6.0842085076728836e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 3.838106931652874e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 34/50\n",
      "Loss: 3.9404745621141046e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 1.557219547976274e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 6.469025538535789e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 4s/step\n",
      "\n",
      " Epoch 35/50\n",
      "Loss: 6.18729172856547e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m10s\u001b[0m 5s/stepLoss: 3.357636887812987e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5s/step Loss: 6.3144307205220684e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 36/50\n",
      "Loss: 2.6767407689476386e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 4.8370678996434435e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5s/stepLoss: 7.141476089600474e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 37/50\n",
      "Loss: 1.7591402865946293e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 4.0579667256679386e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 3.806055974564515e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 38/50\n",
      "Loss: 1.4644449947809335e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 8.933479875850026e-06\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5s/stepLoss: 4.906664980808273e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 39/50\n",
      "Loss: 2.3083408450474963e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 1.2155864169471897e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 4s/stepLoss: 3.881297743646428e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 40/50\n",
      "Loss: 2.888774179155007e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 9.339495591120794e-06\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 1.6943062291829847e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 41/50\n",
      "Loss: 1.3243665307527408e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 2.152194247173611e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5s/stepLoss: 2.2863665435579605e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 42/50\n",
      "Loss: 2.151430817320943e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 8.080283805611543e-06\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5s/stepLoss: 1.541219899081625e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 43/50\n",
      "Loss: 2.1596255464828573e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 1.2148369933129288e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 1.755094126565382e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 44/50\n",
      "Loss: 8.0914451245917e-06\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 2.0400795619934797e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 1.9819341105176136e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 45/50\n",
      "Loss: 1.7505679352325387e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 1.431672899343539e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 2.081793536490295e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 46/50\n",
      "Loss: 9.603947546565905e-06\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 1.7002717868308537e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 2.0314913854235783e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 47/50\n",
      "Loss: 2.9602406357298605e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m8s\u001b[0m 4s/stepLoss: 5.774259989266284e-06\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 8.426743079326116e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 48/50\n",
      "Loss: 1.3541767657443415e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 1.322879506915342e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 1.1842925232485868e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 49/50\n",
      "Loss: 1.0159124030906241e-05\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 2.2281812562141567e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 5s/stepLoss: 1.1582210390770342e-05\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n",
      "\n",
      " Epoch 50/50\n",
      "Loss: 8.478982636006549e-06\n",
      "\u001b[1m1/3\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 5s/stepLoss: 1.325109406025149e-05\n",
      "\u001b[1m2/3\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 5s/stepLoss: 6.58639328321442e-06\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 5s/step\n"
     ]
    }
   ],
   "source": [
    "train(train_data, EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input, test_val, y_true = test_data.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = siamese_model.predict([test_input, test_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 12, 1)\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[66], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mtype\u001b[39m(predictions)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpredictions\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
     ]
    }
   ],
   "source": [
    "type(predictions)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1 if prediction > 0.5 else 0 for prediction in predictions.numpy()]\n",
    "binary_predictions = tf.where(predictions > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., 0., 1., 1., 1., 0., 0., 1., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = Recall()\n",
    "m.update_state(y_true, binary_predictions)\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = Precision()\n",
    "n.update_state(y_true, binary_predictions)\n",
    "n.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(1,2,)\n",
    "plt.imshow(test_input[3])\n",
    "plt.title(\"Input Image\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(test_val[3])\n",
    "plt.title(\"Validation Image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "siamese_model.save('siamese_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('siamese_model.h5', custom_objects={'L1Dist': L1Dist, 'BinaryCrossEntropy': tf.losses.BinaryCrossentropy()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
